{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4DJxtYEGdgqdgCG4BGpSV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LxsaYsTpUdM","executionInfo":{"status":"ok","timestamp":1682530798313,"user_tz":240,"elapsed":19051,"user":{"displayName":"Kaia Gao","userId":"07468833675956455323"}},"outputId":"a5fa6dc6-d66b-463f-82c5-1eb4c498dac0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/03_assignment/04_HRI/DeepFit\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd ./drive/MyDrive/03_assignment/04_HRI/DeepFit"]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUhaGxodpWiO","executionInfo":{"status":"ok","timestamp":1682530807426,"user_tz":240,"elapsed":882,"user":{"displayName":"Kaia Gao","userId":"07468833675956455323"}},"outputId":"5d36b1ff-7a3c-411f-ffbd-dcb792d87ed9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.9.3.0 sounddevice-0.4.6\n"]}]},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from collections import deque\n","from google.colab.patches import cv2_imshow ## only for colab\n","from utils.display import *\n","\n","# Mapping dictionary to map keypoints from Mediapipe to our Classifier model\n","lm_dict = {\n","  0:0 , 1:10, 2:12, 3:14, 4:16, 5:11, 6:13, 7:15, 8:24, 9:26, 10:28, 11:23, 12:25, 13:27, 14:5, 15:2, 16:8, 17:7,\n","}\n","\n","\n","\n","def main():\n","    mode, complexity, smooth_landmarks, enable_segmentation, smooth_segmentation, detectionCon, trackCon, mpPose = set_pose_parameters()\n","    pose = mpPose.Pose(mode, complexity, smooth_landmarks,\n","                                enable_segmentation, smooth_segmentation,\n","                                detectionCon, trackCon)\n","\n","\n","    # Setting video feed variables\n","    cap, count, direction, form, feedback, frame_queue, clf = set_video_feed_variables(\"../demo.mp4\")\n","    \n","\n","\n","    #Start video feed and run workout\n","    while cap.isOpened():\n","        #Getting image from camera\n","        ret, img = cap.read() \n","        #Getting video dimensions\n","        width  = cap.get(3)  \n","        height = cap.get(4)  \n","        \n","        #Convert from BGR (used by cv2) to RGB (used by Mediapipe)\n","        results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        \n","        #Get pose and draw landmarks\n","        img = get_pose(img, results, False)\n","        \n","        # Get landmark list from mediapipe\n","        landmark_list = get_position(img, results, height, width, False)\n","        \n","        #If landmarks exist, get the relevant workout body angles and run workout. The points used are identifiers for specific joints\n","        if len(landmark_list) != 0:\n","\n","            elbow_angle, shoulder_angle, hip_angle, elbow_angle_right, shoulder_angle_right, hip_angle_right, knee_angle = set_body_angles_from_keypoints(get_angle, img, landmark_list)\n","            # print(elbow_angle, shoulder_angle, hip_angle, elbow_angle_right, shoulder_angle_right, hip_angle_right, knee_angle)\n","            workout_name_after_smoothening = set_smoothened_workout_name(lm_dict, convert_mediapipe_keypoints_for_model, frame_queue, clf, landmark_list)    \n","\n","            workout_name_after_smoothening = workout_name_after_smoothening.replace(\"Workout Name:\", \"\").strip()\n","            pushup_success_percentage, pushup_progress_bar = set_percentage_bar_and_text(elbow_angle, shoulder_angle, hip_angle, elbow_angle_right, shoulder_angle_right, hip_angle_right, knee_angle, workout_name_after_smoothening)\n","        \n","                    \n","            #Is the form correct at the start?\n","            form = check_form(elbow_angle, shoulder_angle, hip_angle, elbow_angle_right, shoulder_angle_right, hip_angle_right, knee_angle, form, workout_name_after_smoothening)\n","        \n","            #Full workout motion\n","            \n","            feedback,count,direction = run_full_workout_motion(count, direction, form, elbow_angle, shoulder_angle, hip_angle, elbow_angle_right, shoulder_angle_right, hip_angle_right, knee_angle, pushup_success_percentage, feedback, workout_name_after_smoothening)\n","            \n","     \n","            \n","            #Display workout stats        \n","            display_workout_stats(count, form, feedback, draw_percentage_progress_bar, display_rep_count, show_workout_feedback, show_workout_name_from_model, img, pushup_success_percentage, pushup_progress_bar, workout_name_after_smoothening)\n","            \n","        print(workout_name_after_smoothening,feedback,count)\n","        # Transparent Overlay\n","        overlay = img.copy()\n","        x, y, w, h = 75, 10, 500, 150\n","        cv2.rectangle(img, (x, y), (x+w, y+h), (255,255,255), -1)      \n","        alpha = 0.8  # Transparency factor.\n","        # Following line overlays transparent rectangle over the image\n","        image_new = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)          \n","        # cv2_imshow(image_new)#use it only on Colab\n","        #cv2.imshow('DEEPFIT Workout Trainer', image_new) \n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","            \n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_asrxBevpfSy","executionInfo":{"status":"error","timestamp":1682531387020,"user_tz":240,"elapsed":9429,"user":{"displayName":"Kaia Gao","userId":"07468833675956455323"}},"outputId":"c355a3da-637b-4f3a-fb72-14d470f676bd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Down 0\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Up 0.5\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Down 1.0\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Up 1.5\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Down 2.0\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Up 2.5\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Down 3.0\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n","jumping_jacks Feedback: Go Up 3.5\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-6cabad2eeb34>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-6cabad2eeb34>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#Convert from BGR (used by cv2) to RGB (used by Mediapipe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#Get pose and draw landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mediapipe/python/solutions/pose.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# output stream names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}